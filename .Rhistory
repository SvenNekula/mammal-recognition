fit(trainx,
trainLabels,
epochs = 56,
batch_size =120,
validation_split = 0.2)
#evaluation and predtiction - train data
model %>% evaluate(trainx, trainLabels)
#creating model
model <- keras_model_sequential()
model %>%
layer_dense(units = 256, activation = "relu", input_shape = c(6912)) %>%
layer_dense(units = 128, activation = "relu") %>%
layer_dense(units = 3, activation = "softmax")
summary(model)
#compiling model
model %>%
compile(loss = "categorical_crossentropy",
optimizer = optimizer_rmsprop(),
metrics = c("accuracy"))
#fitting model
history <- model %>%
fit(trainx,
trainLabels,
epochs = 50,
batch_size =32,
validation_split = 0.2)
#evaluation and predtiction - train data
model %>% evaluate(trainx, trainLabels)
prediction <- model %>% predict_classes(trainx)
table(Predicted = prediction, Actual = trainy)
probability <- model %>% predict_proba(trainx)
cbind(probability, Predicted = prediction, Actual=trainy)
#creating model
model <- keras_model_sequential()
summary(model)
#creating model
model <- keras_model_sequential()
model %>%
layer_dense(units = 256, activation = "relu", input_shape = c(6912)) %>%
layer_dense(units = 128, activation = "relu") %>%
layer_dense(units = 3, activation = "softmax")
summary(model)
#compiling model
model %>%
compile(loss = "categorical_crossentropy",
optimizer = optimizer_rmsprop(),
metrics = c("accuracy"))
#fitting model
history <- model %>%
fit(trainx,
trainLabels,
epochs = 100,
batch_size =32,
validation_split = 0.2)
plot(history)
#evaluation and predtiction - train data
model %>% evaluate(trainx, trainLabels)
prediction <- model %>% predict_classes(trainx)
table(Predicted = prediction, Actual = trainy)
probability <- model %>% predict_proba(trainx)
cbind(probability, Predicted = prediction, Actual=trainy)
#creating model
model <- keras_model_sequential()
model %>%
layer_dense(units = 512, activation = "relu", input_shape = c(6912)) %>%
layer_dense(units = 256, activation = "relu") %>%
layer_dense(units = 3, activation = "softmax")
summary(model)
#compiling model
model %>%
compile(loss = "categorical_crossentropy",
optimizer = optimizer_rmsprop(),
metrics = c("accuracy"))
#fitting model
history <- model %>%
fit(trainx,
trainLabels,
epochs = 100,
batch_size =32,
validation_split = 0.2)
plot(history)
#evaluation and predtiction - train data
model %>% evaluate(trainx, trainLabels)
prediction <- model %>% predict_classes(trainx)
table(Predicted = prediction, Actual = trainy)
probability <- model %>% predict_proba(trainx)
cbind(probability, Predicted = prediction, Actual=trainy)
#creating model
model <- keras_model_sequential()
model %>%
layer_dense(units = 512, activation = "relu", input_shape = c(6912)) %>%
layer_dense(units = 256, activation = "relu") %>%
layer_dense(units = 3, activation = "softmax")
summary(model)
#compiling model
model %>%
compile(loss = "categorical_crossentropy",
optimizer = optimizer_rmsprop(),
metrics = c("accuracy"))
#fitting model
history <- model %>%
fit(trainx,
trainLabels,
epochs = 100,
batch_size =32,
validation_split = 0.2)
#evaluation and predtiction - train data
model %>% evaluate(trainx, trainLabels)
prediction <- model %>% predict_classes(trainx)
table(Predicted = prediction, Actual = trainy)
#creating model
model <- keras_model_sequential()
model %>%
layer_dense(units = 256, activation = "relu", input_shape = c(6912)) %>%
layer_dense(units = 128, activation = "relu") %>%
layer_dense(units = 3, activation = "softmax")
summary(model)
#compiling model
model %>%
compile(loss = "categorical_crossentropy",
optimizer = optimizer_rmsprop(),
metrics = c("accuracy"))
#fitting model
history <- model %>%
fit(trainx,
trainLabels,
epochs = 100,
batch_size =32,
validation_split = 0.2)
#evaluation and predtiction - train data
model %>% evaluate(trainx, trainLabels)
#creating model
model <- keras_model_sequential()
model %>%
layer_dense(units = 256, activation = "relu", input_shape = c(6912)) %>%
layer_dense(units = 128, activation = "relu") %>%
layer_dense(units = 3, activation = "softmax")
summary(model)
#compiling model
model %>%
compile(loss = "categorical_crossentropy",
optimizer = optimizer_rmsprop(),
metrics = c("accuracy"))
#fitting model
history <- model %>%
fit(trainx,
trainLabels,
epochs = 59,
batch_size =32,
validation_split = 0.2)
#evaluation and predtiction - train data
model %>% evaluate(trainx, trainLabels)
#compiling model
model %>%
compile(loss = "categorical_crossentropy",
optimizer = optimizer_rmsprop(),
metrics = c("accuracy"))
#fitting model
history <- model %>%
fit(trainx,
trainLabels,
epochs = 45,
batch_size =32,
validation_split = 0.2)
#evaluation and predtiction - train data
model %>% evaluate(trainx, trainLabels)
#creating model
model <- keras_model_sequential()
model %>%
layer_dense(units = 256, activation = "relu", input_shape = c(6912)) %>%
layer_dense(units = 128, activation = "relu") %>%
layer_dense(units = 3, activation = "softmax")
summary(model)
#compiling model
model %>%
compile(loss = "categorical_crossentropy",
optimizer = optimizer_rmsprop(),
metrics = c("accuracy"))
#fitting model
history <- model %>%
fit(trainx,
trainLabels,
epochs = 50,
batch_size =32,
validation_split = 0.2)
#evaluation and predtiction - train data
model %>% evaluate(trainx, trainLabels)
#creating model
model <- keras_model_sequential()
model %>%
layer_dense(units = 256, activation = "relu", input_shape = c(6912)) %>%
layer_dense(units = 128, activation = "relu") %>%
layer_dense(units = 3, activation = "softmax")
summary(model)
#compiling model
model %>%
compile(loss = "categorical_crossentropy",
optimizer = optimizer_rmsprop(),
metrics = c("accuracy"),
callback = EarlyStopping(monitor = "val_loss"))
#compiling model
model %>%
compile(loss = "categorical_crossentropy",
optimizer = optimizer_rmsprop(),
metrics = c("accuracy"),
callback = list(EarlyStopping(monitor = "val_loss")))
#creating model
model <- keras_model_sequential()
model %>%
layer_dense(units = 256, activation = "relu", input_shape = c(6912)) %>%
layer_dense(units = 128, activation = "relu") %>%
layer_dense(units = 3, activation = "softmax")
summary(model)
#compiling model
model %>%
compile(loss = "categorical_crossentropy",
optimizer = optimizer_rmsprop(),
metrics = c("accuracy"),
callbacks = list(callback_early_stopping(monitor="val_loss")))
#creating model
model <- keras_model_sequential()
model %>%
layer_dense(units = 256, activation = "relu", input_shape = c(6912)) %>%
layer_dense(units = 128, activation = "relu") %>%
layer_dense(units = 3, activation = "softmax")
summary(model)
#compiling model
model %>%
compile(loss = "categorical_crossentropy",
optimizer = optimizer_rmsprop(),
metrics = c("accuracy"))
#fitting model
history <- model %>%
fit(trainx,
trainLabels,
epochs = 50,
batch_size =32,
validation_split = 0.2,
callback_early_stopping(monitor = "val_loss"))
#fitting model
history <- model %>%
fit(trainx,
trainLabels,
epochs = 50,
batch_size =32,
validation_split = 0.2,
callback = callback_early_stopping(monitor = "val_loss"))
#creating model
model <- keras_model_sequential()
model %>%
layer_dense(units = 256, activation = "relu", input_shape = c(6912)) %>%
layer_dense(units = 128, activation = "relu") %>%
layer_dense(units = 3, activation = "softmax")
summary(model)
#compiling model
model %>%
compile(loss = "categorical_crossentropy",
optimizer = optimizer_rmsprop(),
metrics = c("accuracy"))
#fitting model
history <- model %>%
fit(trainx,
trainLabels,
epochs = 50,
batch_size =32,
validation_split = 0.2,
callback = callback_early_stopping(monitor = "val_loss", patience = 10))
#creating model
model <- keras_model_sequential()
model %>%
layer_dense(units = 256, activation = "relu", input_shape = c(6912)) %>%
layer_dense(units = 128, activation = "relu") %>%
layer_dense(units = 3, activation = "softmax")
summary(model)
#compiling model
model %>%
compile(loss = "categorical_crossentropy",
optimizer = optimizer_rmsprop(),
metrics = c("accuracy"))
#fitting model
history <- model %>%
fit(trainx,
trainLabels,
epochs = 50,
batch_size =32,
validation_split = 0.2,
callback = callback_early_stopping(monitor = "loss"))
#creating model
model <- keras_model_sequential()
model %>%
layer_dense(units = 256, activation = "relu", input_shape = c(6912)) %>%
layer_dense(units = 128, activation = "relu") %>%
layer_dense(units = 3, activation = "softmax")
summary(model)
#compiling model
model %>%
compile(loss = "categorical_crossentropy",
optimizer = optimizer_rmsprop(),
metrics = c("accuracy"))
#fitting model
history <- model %>%
fit(trainx,
trainLabels,
epochs = 50,
batch_size =32,
validation_split = 0.2,
callback = callback_early_stopping(monitor = "loss", patience=5))
#fitting model
history <- model %>%
fit(trainx,
trainLabels,
epochs = 50,
batch_size =32,
validation_split = 0.2,
callback = callback_early_stopping(monitor = "loss", patience=20))
#evaluation and predtiction - train data
model %>% evaluate(trainx, trainLabels)
plot(history)
#creating model
model <- keras_model_sequential()
model %>%
layer_dense(units = 256, activation = "relu", input_shape = c(6912)) %>%
layer_dense(units = 128, activation = "relu") %>%
layer_dense(units = 3, activation = "softmax")
summary(model)
#compiling model
model %>%
compile(loss = "categorical_crossentropy",
optimizer = optimizer_rmsprop(),
metrics = c("accuracy"))
#fitting model
history <- model %>%
fit(trainx,
trainLabels,
epochs = 50,
batch_size =32,
validation_split = 0.2,
callback = callback_early_stopping(monitor = "loss", patience=10))
#evaluation and predtiction - train data
model %>% evaluate(trainx, trainLabels)
#creating model
model <- keras_model_sequential()
model %>%
layer_dense(units = 256, activation = "relu", input_shape = c(6912)) %>%
layer_dense(units = 128, activation = "relu") %>%
layer_dense(units = 3, activation = "softmax")
summary(model)
#compiling model
model %>%
compile(loss = "categorical_crossentropy",
optimizer = optimizer_rmsprop(),
metrics = c("accuracy"))
#fitting model
history <- model %>%
fit(trainx,
trainLabels,
epochs = 50,
batch_size =32,
validation_split = 0.2,
callback = callback_early_stopping(monitor = "accuracy", patience=10))
#creating model
model <- keras_model_sequential()
model %>%
layer_dense(units = 256, activation = "relu", input_shape = c(6912)) %>%
layer_dense(units = 128, activation = "relu") %>%
layer_dense(units = 3, activation = "softmax")
summary(model)
#compiling model
model %>%
compile(loss = "categorical_crossentropy",
optimizer = optimizer_rmsprop(),
metrics = c("accuracy"))
#fitting model
history <- model %>%
fit(trainx,
trainLabels,
epochs = 50,
batch_size =32,
validation_split = 0.2,
callback = callback_early_stopping(monitor = c("accuracy", "loss", "val_loss"), patience=10))
#creating model
model <- keras_model_sequential()
model %>%
layer_dense(units = 256, activation = "relu", input_shape = c(6912)) %>%
layer_dense(units = 128, activation = "relu") %>%
layer_dense(units = 3, activation = "softmax")
summary(model)
#compiling model
model %>%
compile(loss = "categorical_crossentropy",
optimizer = optimizer_rmsprop(),
metrics = c("accuracy"))
#fitting model
history <- model %>%
fit(trainx,
trainLabels,
epochs = 250,
batch_size =32,
validation_split = 0.2)
#creating model
model <- keras_model_sequential()
model %>%
layer_dense(units = 256, activation = "relu", input_shape = c(6912)) %>%
layer_dense(units = 128, activation = "relu") %>%
layer_dense(units = 3, activation = "softmax")
summary(model)
#compiling model
model %>%
compile(loss = "categorical_crossentropy",
optimizer = optimizer_rmsprop(),
metrics = c("accuracy"))
#fitting model
history <- model %>%
fit(trainx,
trainLabels,
epochs = 250,
batch_size =32,
validation_split = 0.2,
callback = callback_early_stopping(monitor = "val_loss", patience = 20))
#creating model
model <- keras_model_sequential()
model %>%
layer_dense(units = 256, activation = "relu", input_shape = c(6912)) %>%
layer_dense(units = 128, activation = "relu") %>%
layer_dense(units = 3, activation = "softmax")
summary(model)
#compiling model
model %>%
compile(loss = "categorical_crossentropy",
optimizer = optimizer_rmsprop(),
metrics = c("accuracy"))
#fitting model
history <- model %>%
fit(trainx,
trainLabels,
epochs = 250,
batch_size =32,
validation_split = 0.2,
callback = callback_early_stopping(monitor = "val_loss", patience = 50))
#evaluation and predtiction - train data
model %>% evaluate(trainx, trainLabels)
#creating model
model <- keras_model_sequential()
#creating model
model <- keras_model_sequential()
model %>%
layer_dense(units = 256, activation = "relu", input_shape = c(6912)) %>%
layer_dense(units = 128, activation = "relu") %>%
layer_dense(units = 3, activation = "softmax")
summary(model)
#compiling model
model %>%
compile(loss = "categorical_crossentropy",
optimizer = optimizer_rmsprop(),
metrics = c("accuracy"))
#fitting model
history <- model %>%
fit(trainx,
trainLabels,
epochs = 250,
batch_size =32,
validation_split = 0.2,
callback = callback_early_stopping(monitor = "val_loss", patience = 30))
#evaluation and predtiction - train data
model %>% evaluate(trainx, trainLabels)
#creating model
model <- keras_model_sequential()
model %>%
layer_dense(units = 256, activation = "relu", input_shape = c(6912)) %>%
layer_dense(units = 128, activation = "relu") %>%
layer_dense(units = 3, activation = "softmax")
summary(model)
#compiling model
model %>%
compile(loss = "categorical_crossentropy",
optimizer = optimizer_rmsprop(),
metrics = c("accuracy"))
#fitting model
history <- model %>%
fit(trainx,
trainLabels,
epochs = 250,
batch_size =32,
validation_split = 0.2,
callback = callback_early_stopping(monitor = "val_loss", patience = 40))
#evaluation and predtiction - train data
model %>% evaluate(trainx, trainLabels)
#creating model
model <- keras_model_sequential()
model %>%
layer_dense(units = 256, activation = "relu", input_shape = c(6912)) %>%
layer_dense(units = 128, activation = "relu") %>%
layer_dense(units = 3, activation = "softmax")
summary(model)
#compiling model
model %>%
compile(loss = "categorical_crossentropy",
optimizer = optimizer_rmsprop(),
metrics = c("accuracy"))
#fitting model
history <- model %>%
fit(trainx,
trainLabels,
epochs = 500,
batch_size =32,
validation_split = 0.2,
callback = callback_early_stopping(monitor = "val_loss", patience = 50))
#evaluation and predtiction - train data
model %>% evaluate(trainx, trainLabels)
prediction <- model %>% predict_classes(trainx)
probability <- model %>% predict_proba(trainx)
cbind(probability, Predicted = prediction, Actual=trainy)
